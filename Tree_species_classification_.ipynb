{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSYenBJQ2v5CLNjAE4vSVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Galaxicitti/Tree-species-classification/blob/main/Tree_species_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kailas93/Tree_species.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDMtamFX8axj",
        "outputId": "c248ed97-8a6f-4294-c6d9-8b4dbd459bef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Tree_species' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "\n",
        "# # # Unzip the dataset\n",
        "# zip_path = \"/content/archive(1).zip\"\n",
        "extract_dir = \"5M_trees\"\n",
        "\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Define which columns to keep\n",
        "selected_columns = [\n",
        "    'common_name', 'scientific_name', 'city', 'state',\n",
        "    'longitude_coordinate', 'latitude_coordinate', 'address', 'condition',\n",
        "    'native', 'height_binned_M', 'diameter_breast_height_binned_CM',\n",
        "    'location_type', 'zipcode', 'neighborhood', 'location_name', 'ward',\n",
        "    'district', 'overhead_utility', 'diameter_breast_height_CM', 'height_M'\n",
        "]\n",
        "\n",
        "# Check if CSV files contain actual data or are Git LFS pointers\n",
        "exclude_files = {'Column_Headers_Dryad.csv', 'README_Dryad.txt'}\n",
        "csv_files = [f for f in glob.glob(os.path.join(extract_dir, \"*.csv\")) if os.path.basename(f) not in exclude_files]\n",
        "\n",
        "# Check if we have real data\n",
        "if csv_files:\n",
        "    sample_file = csv_files[0]\n",
        "    with open(sample_file, 'r') as f:\n",
        "        first_line = f.readline().strip()\n",
        "\n",
        "    if \"git-lfs\" in first_line:\n",
        "        print(\"‚ö†Ô∏è  CSV files are Git LFS pointers, not actual data!\")\n",
        "        print(\"üì• Please download real data from: https://datadryad.org/stash/dataset/doi:10.5061/dryad.2rbnzs7hs\")\n",
        "        print(\"üîÑ Creating sample data for demonstration...\")\n",
        "\n",
        "        # Create sample data for demonstration\n",
        "        np.random.seed(42)\n",
        "        n_samples = 10000\n",
        "\n",
        "        tree_species = ['Oak', 'Maple', 'Pine', 'Birch', 'Cedar', 'Elm', 'Willow', 'Poplar', 'Ash', 'Cherry']\n",
        "        cities = ['Austin', 'Dallas', 'Houston', 'Seattle', 'Portland', 'Denver', 'Phoenix', 'Chicago', 'Boston', 'New York']\n",
        "        states = ['TX', 'WA', 'OR', 'CO', 'AZ', 'IL', 'MA', 'NY']\n",
        "\n",
        "        sample_data = {\n",
        "            'common_name': np.random.choice(tree_species, n_samples),\n",
        "            'scientific_name': [f\"Species_{i}\" for i in range(n_samples)],\n",
        "            'city': np.random.choice(cities, n_samples),\n",
        "            'state': np.random.choice(states, n_samples),\n",
        "            'longitude_coordinate': np.random.uniform(-125.0, -67.0, n_samples),\n",
        "            'latitude_coordinate': np.random.uniform(25.0, 49.0, n_samples),\n",
        "            'address': [f\"Address_{i}\" for i in range(n_samples)],\n",
        "            'condition': np.random.choice(['Good', 'Fair', 'Poor'], n_samples),\n",
        "            'native': np.random.choice(['Native', 'Non-native'], n_samples),\n",
        "            'height_binned_M': np.random.uniform(1.0, 30.0, n_samples),\n",
        "            'diameter_breast_height_binned_CM': np.random.uniform(5.0, 100.0, n_samples),\n",
        "            'location_type': np.random.choice(['Street', 'Park', 'Yard'], n_samples),\n",
        "            'zipcode': np.random.randint(10000, 99999, n_samples),\n",
        "            'neighborhood': [f\"Neighborhood_{i%50}\" for i in range(n_samples)],\n",
        "            'location_name': [f\"Location_{i}\" for i in range(n_samples)],\n",
        "            'ward': np.random.randint(1, 20, n_samples),\n",
        "            'district': np.random.randint(1, 10, n_samples),\n",
        "            'overhead_utility': np.random.choice(['Yes', 'No'], n_samples),\n",
        "            'diameter_breast_height_CM': np.random.uniform(5.0, 100.0, n_samples),\n",
        "            'height_M': np.random.uniform(1.0, 30.0, n_samples)\n",
        "        }\n",
        "\n",
        "        merged_df = pd.DataFrame(sample_data)\n",
        "        print(f\"‚úÖ Created sample dataset with {len(merged_df):,} records\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚úÖ Found real CSV data files!\")\n",
        "        # Original code for processing real CSV files\n",
        "        df_list = []\n",
        "        for file in csv_files:\n",
        "            df = pd.read_csv(file, low_memory=False)\n",
        "            filtered_df = df[selected_columns].copy()\n",
        "            df_list.append(filtered_df)\n",
        "\n",
        "        merged_df = pd.concat(df_list, ignore_index=True)\n",
        "        print(f\"‚úÖ Processed {len(csv_files)} CSV files with {len(merged_df):,} records\")\n",
        "else:\n",
        "    print(\"‚ùå No CSV files found!\")\n",
        "    print(\"üîÑ Creating sample data for demonstration...\")\n",
        "\n",
        "    # Create sample data for demonstration\n",
        "    np.random.seed(42)\n",
        "    n_samples = 10000\n",
        "\n",
        "    tree_species = ['Oak', 'Maple', 'Pine', 'Birch', 'Cedar', 'Elm', 'Willow', 'Poplar', 'Ash', 'Cherry']\n",
        "    cities = ['Austin', 'Dallas', 'Houston', 'Seattle', 'Portland', 'Denver', 'Phoenix', 'Chicago', 'Boston', 'New York']\n",
        "    states = ['TX', 'WA', 'OR', 'CO', 'AZ', 'IL', 'MA', 'NY']\n",
        "\n",
        "    sample_data = {\n",
        "        'common_name': np.random.choice(tree_species, n_samples),\n",
        "        'scientific_name': [f\"Species_{i}\" for i in range(n_samples)],\n",
        "        'city': np.random.choice(cities, n_samples),\n",
        "        'state': np.random.choice(states, n_samples),\n",
        "        'longitude_coordinate': np.random.uniform(-125.0, -67.0, n_samples),\n",
        "        'latitude_coordinate': np.random.uniform(25.0, 49.0, n_samples),\n",
        "        'address': [f\"Address_{i}\" for i in range(n_samples)],\n",
        "        'condition': np.random.choice(['Good', 'Fair', 'Poor'], n_samples),\n",
        "        'native': np.random.choice(['Native', 'Non-native'], n_samples),\n",
        "        'height_binned_M': np.random.uniform(1.0, 30.0, n_samples),\n",
        "        'diameter_breast_height_binned_CM': np.random.uniform(5.0, 100.0, n_samples),\n",
        "        'location_type': np.random.choice(['Street', 'Park', 'Yard'], n_samples),\n",
        "        'zipcode': np.random.randint(10000, 99999, n_samples),\n",
        "        'neighborhood': [f\"Neighborhood_{i%50}\" for i in range(n_samples)],\n",
        "        'location_name': [f\"Location_{i}\" for i in range(n_samples)],\n",
        "        'ward': np.random.randint(1, 20, n_samples),\n",
        "        'district': np.random.randint(1, 10, n_samples),\n",
        "        'overhead_utility': np.random.choice(['Yes', 'No'], n_samples),\n",
        "        'diameter_breast_height_CM': np.random.uniform(5.0, 100.0, n_samples),\n",
        "        'height_M': np.random.uniform(1.0, 30.0, n_samples)\n",
        "    }\n",
        "\n",
        "    merged_df = pd.DataFrame(sample_data)\n",
        "    print(f\"‚úÖ Created sample dataset with {len(merged_df):,} records\")\n",
        "\n",
        "\n",
        "# Add tree_id column\n",
        "if not merged_df.empty:\n",
        "    merged_df.insert(0, 'tree_id', ['tree_' + str(i) for i in range(1, len(merged_df) + 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPcbyzoM8WYk",
        "outputId": "cf61365d-c122-46c9-8def-e6743113aaee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå No CSV files found!\n",
            "üîÑ Creating sample data for demonstration...\n",
            "‚úÖ Created sample dataset with 10,000 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "LxVCfTSGMLDE",
        "outputId": "8d079e1d-163e-443e-b5aa-c42fac2ae1ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tree_id                             0\n",
              "common_name                         0\n",
              "scientific_name                     0\n",
              "city                                0\n",
              "state                               0\n",
              "longitude_coordinate                0\n",
              "latitude_coordinate                 0\n",
              "address                             0\n",
              "condition                           0\n",
              "native                              0\n",
              "height_binned_M                     0\n",
              "diameter_breast_height_binned_CM    0\n",
              "location_type                       0\n",
              "zipcode                             0\n",
              "neighborhood                        0\n",
              "location_name                       0\n",
              "ward                                0\n",
              "district                            0\n",
              "overhead_utility                    0\n",
              "diameter_breast_height_CM           0\n",
              "height_M                            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tree_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>common_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scientific_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude_coordinate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude_coordinate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>address</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height_binned_M</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diameter_breast_height_binned_CM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location_type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neighborhood</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ward</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>district</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overhead_utility</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diameter_breast_height_CM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height_M</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with more than 3,038,500 missing values\n",
        "threshold = 3038501\n",
        "merged_df = merged_df.loc[:, merged_df.isnull().sum() <= threshold]"
      ],
      "metadata": {
        "id": "Qj8B9PtWMQGE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is no longer needed as the sample data does not have the same missing value characteristics\n",
        "# merged_df = merged_df.drop(columns=['diameter_breast_height_binned_CM'])"
      ],
      "metadata": {
        "id": "zgIVEBUeMUQ3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.dropna(subset=[\n",
        "    'common_name',\n",
        "    'scientific_name',\n",
        "    'longitude_coordinate',\n",
        "    'latitude_coordinate',\n",
        "    'condition',\n",
        "    'diameter_breast_height_CM','address', 'city'\n",
        "])\n"
      ],
      "metadata": {
        "id": "wv8wrXmFMXXM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "hrxAvkmUMbfa",
        "outputId": "1db27336-f1de-4231-b9c1-a8ba898b6cbd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tree_id                             0\n",
              "common_name                         0\n",
              "scientific_name                     0\n",
              "city                                0\n",
              "state                               0\n",
              "longitude_coordinate                0\n",
              "latitude_coordinate                 0\n",
              "address                             0\n",
              "condition                           0\n",
              "native                              0\n",
              "height_binned_M                     0\n",
              "diameter_breast_height_binned_CM    0\n",
              "location_type                       0\n",
              "zipcode                             0\n",
              "neighborhood                        0\n",
              "location_name                       0\n",
              "ward                                0\n",
              "district                            0\n",
              "overhead_utility                    0\n",
              "diameter_breast_height_CM           0\n",
              "height_M                            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tree_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>common_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scientific_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude_coordinate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude_coordinate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>address</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height_binned_M</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diameter_breast_height_binned_CM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location_type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neighborhood</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>location_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ward</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>district</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overhead_utility</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diameter_breast_height_CM</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height_M</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Remove tree species with < 2 samples\n",
        "species_counts = merged_df['common_name'].value_counts()\n",
        "valid_species = species_counts[species_counts >= 3].index.tolist()\n",
        "\n",
        "# Keep only valid species\n",
        "filtered_df = merged_df[merged_df['common_name'].isin(valid_species)].copy()\n",
        "\n",
        "# Verify the filtering worked\n",
        "assert filtered_df['common_name'].value_counts().min() >= 3, \"Still has species with < 2 samples!\"\n",
        "\n",
        "# Continue with filtered data\n",
        "data = filtered_df.copy()\n"
      ],
      "metadata": {
        "id": "zf2DS8zfMd5d"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['common_name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "2XGE58g_MiJX",
        "outputId": "7c56564e-a28d-40aa-f413-262a095487b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "common_name\n",
              "Oak       1053\n",
              "Cherry    1034\n",
              "Elm       1021\n",
              "Willow    1017\n",
              "Pine       996\n",
              "Ash        994\n",
              "Maple      985\n",
              "Birch      971\n",
              "Poplar     967\n",
              "Cedar      962\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>common_name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Oak</th>\n",
              "      <td>1053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cherry</th>\n",
              "      <td>1034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Elm</th>\n",
              "      <td>1021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Willow</th>\n",
              "      <td>1017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pine</th>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ash</th>\n",
              "      <td>994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Maple</th>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Birch</th>\n",
              "      <td>971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Poplar</th>\n",
              "      <td>967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cedar</th>\n",
              "      <td>962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "\n",
        "# Load data\n",
        "df = filtered_df.copy()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "\n",
        "# Load data\n",
        "df = merged_df.copy()\n",
        "\n",
        "# Optional: Simplify to genus\n",
        "df['genus'] = df['scientific_name'].apply(lambda x: x.split()[0])\n",
        "\n",
        "# Encode categorical variables (native, city, state)\n",
        "df['native_encoded'] = df['native'].astype('category').cat.codes\n",
        "df['city_encoded'] = df['city'].astype('category').cat.codes\n",
        "df['state_encoded'] = df['state'].astype('category').cat.codes\n",
        "\n",
        "# Features to use\n",
        "feature_cols = ['latitude_coordinate', 'longitude_coordinate', 'diameter_breast_height_CM',\n",
        "                'native_encoded', 'city_encoded', 'state_encoded']\n",
        "X = df[feature_cols]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit Nearest Neighbors model\n",
        "nn_model = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')  # can tune n_neighbors\n",
        "nn_model.fit(X_scaled)\n",
        "\n",
        "# Prediction function\n",
        "def recommend_species(lat, lon, diameter_cm, native, city, state, top_n=5):\n",
        "    # Encode input\n",
        "    native_code = df['native'].astype('category').cat.categories.get_loc(native)\n",
        "    city_code = df['city'].astype('category').cat.categories.get_loc(city)\n",
        "    state_code = df['state'].astype('category').cat.categories.get_loc(state)\n",
        "\n",
        "    input_features = np.array([[lat, lon, diameter_cm, native_code, city_code, state_code]])\n",
        "    input_scaled = scaler.transform(input_features)\n",
        "\n",
        "    distances, indices = nn_model.kneighbors(input_scaled)\n",
        "\n",
        "    # Get common names or genera from neighbors\n",
        "    neighbors = df.iloc[indices[0]]\n",
        "    species_counts = Counter(neighbors['common_name'])  # or use 'genus'\n",
        "\n",
        "    # Top-N species\n",
        "    top_species = species_counts.most_common(top_n)\n",
        "    return top_species\n",
        "# Optional: Simplify to genus\n",
        "df['genus'] = df['scientific_name'].apply(lambda x: x.split()[0])\n",
        "\n",
        "# Encode categorical variables (native, city, state)\n",
        "df['native_encoded'] = df['native'].astype('category').cat.codes\n",
        "df['city_encoded'] = df['city'].astype('category').cat.codes\n",
        "df['state_encoded'] = df['state'].astype('category').cat.codes\n",
        "\n",
        "# Features to use\n",
        "feature_cols = ['latitude_coordinate', 'longitude_coordinate', 'diameter_breast_height_CM',\n",
        "                'native_encoded', 'city_encoded', 'state_encoded']\n",
        "X = df[feature_cols]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit Nearest Neighbors model\n",
        "nn_model = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')  # can tune n_neighbors\n",
        "nn_model.fit(X_scaled)\n",
        "\n",
        "# Prediction function\n",
        "def recommend_species(lat, lon, diameter_cm, native, city, state, top_n=5):\n",
        "    # Encode input\n",
        "    native_code = df['native'].astype('category').cat.categories.get_loc(native)\n",
        "    city_code = df['city'].astype('category').cat.categories.get_loc(city)\n",
        "    state_code = df['state'].astype('category').cat.categories.get_loc(state)\n",
        "\n",
        "    input_features = np.array([[lat, lon, diameter_cm, native_code, city_code, state_code]])\n",
        "    input_scaled = scaler.transform(input_features)\n",
        "\n",
        "    distances, indices = nn_model.kneighbors(input_scaled)\n",
        "\n",
        "    # Get common names or genera from neighbors\n",
        "    neighbors = df.iloc[indices[0]]\n",
        "    species_counts = Counter(neighbors['common_name'])  # or use 'genus'\n",
        "\n",
        "    # Top-N species\n",
        "    top_species = species_counts.most_common(top_n)\n",
        "    return top_species"
      ],
      "metadata": {
        "id": "P6MocRAXMlJE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "def evaluate_recommender(X_scaled, df, model, top_k=5, sample_size=1000):\n",
        "    correct = 0\n",
        "    ranks = []\n",
        "\n",
        "    for i in tqdm(range(sample_size)):\n",
        "        x_query = X_scaled[i].reshape(1, -1)\n",
        "        distances, indices = model.kneighbors(x_query)\n",
        "\n",
        "        # exclude itself\n",
        "        neighbor_indices = [idx for idx in indices[0] if idx != i][:top_k]\n",
        "        true_species = df.iloc[i]['common_name']\n",
        "        neighbor_species = df.iloc[neighbor_indices]['common_name'].tolist()\n",
        "\n",
        "        if true_species in neighbor_species:\n",
        "            correct += 1\n",
        "            ranks.append(neighbor_species.index(true_species) + 1)\n",
        "        else:\n",
        "            ranks.append(0)\n",
        "\n",
        "    hit_rate = correct / sample_size\n",
        "    mean_rank = sum([1/r for r in ranks if r > 0]) / sample_size\n",
        "\n",
        "    print(f\"Top-{top_k} Hit Rate: {hit_rate:.4f}\")\n",
        "    print(f\"Mean Reciprocal Rank: {mean_rank:.4f}\")\n",
        "    return hit_rate, mean_rank\n",
        "\n",
        "# Run evaluation on a 1000-sample subset\n",
        "evaluate_recommender(X_scaled, df, nn_model, top_k=5, sample_size=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mjuvfnLMpP-",
        "outputId": "0fe7cc50-58f7-4df3-abda-6c1e4b44ab07"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:01<00:00, 945.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 Hit Rate: 0.3870\n",
            "Mean Reciprocal Rank: 0.1982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.387, 0.19821666666666674)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save scaler and model\n",
        "import joblib\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "joblib.dump(nn_model, 'nn_model.joblib')\n",
        "\n",
        "# Also save the dataframe with encoded columns (needed for categories and lookup)\n",
        "df.to_pickle('tree_data.pkl')\n",
        "\n",
        "print(\"Saved scaler, model and data!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzNxiXmzMveI",
        "outputId": "ce02794b-f4fd-4cd7-daab-158e43a4d248"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved scaler, model and data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_common_locations_for_species(tree_name, top_n=10):\n",
        "    \"\"\"\n",
        "    Given a tree common name, return the top N most frequent locations.\n",
        "    \"\"\"\n",
        "    species_df = df[df['common_name'] == tree_name]\n",
        "\n",
        "    if species_df.empty:\n",
        "        return f\"No records found for species: {tree_name}\"\n",
        "\n",
        "    # You can group by city/state or full address\n",
        "    location_counts = species_df.groupby(['city', 'state']) \\\n",
        "                                .size().reset_index(name='count') \\\n",
        "                                .sort_values(by='count', ascending=False) \\\n",
        "                                .head(top_n)\n",
        "\n",
        "    return location_counts\n"
      ],
      "metadata": {
        "id": "XRfbr-eHMydo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the location function with tree species that exist in our sample data\n",
        "print(\"Available tree species in our data:\")\n",
        "print(df['common_name'].value_counts().head(10))\n",
        "\n",
        "# Test with Oak which should exist\n",
        "tree_name = 'Oak'\n",
        "top_locations = get_common_locations_for_species(tree_name)  # Fixed: removed df parameter\n",
        "print(f\"\\nTop locations where '{tree_name}' is commonly found:\")\n",
        "if isinstance(top_locations, str):  # Check if it's error message\n",
        "    print(top_locations)\n",
        "elif top_locations.empty:\n",
        "    print(f\"No records found for species: {tree_name}\")\n",
        "else:\n",
        "    print(top_locations)\n",
        "\n",
        "# Test with another species\n",
        "tree_name = 'Pine'\n",
        "top_locations = get_common_locations_for_species(tree_name)  # Fixed: removed df parameter\n",
        "print(f\"\\nTop locations where '{tree_name}' is commonly found:\")\n",
        "if isinstance(top_locations, str):  # Check if it's error message\n",
        "    print(top_locations)\n",
        "elif top_locations.empty:\n",
        "    print(f\"No records found for species: {tree_name}\")\n",
        "else:\n",
        "    print(top_locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gslv2U1EM1j1",
        "outputId": "8a8c4dc7-5103-4cb7-8899-f292aee2076c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available tree species in our data:\n",
            "common_name\n",
            "Oak       1053\n",
            "Cherry    1034\n",
            "Elm       1021\n",
            "Willow    1017\n",
            "Pine       996\n",
            "Ash        994\n",
            "Maple      985\n",
            "Birch      971\n",
            "Poplar     967\n",
            "Cedar      962\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top locations where 'Oak' is commonly found:\n",
            "        city state  count\n",
            "0     Austin    AZ     22\n",
            "34    Denver    IL     21\n",
            "59   Phoenix    MA     21\n",
            "4     Austin    NY     19\n",
            "15    Boston    WA     19\n",
            "21   Chicago    OR     19\n",
            "23   Chicago    WA     18\n",
            "3     Austin    MA     18\n",
            "51  New York    MA     18\n",
            "27    Dallas    MA     17\n",
            "\n",
            "Top locations where 'Pine' is commonly found:\n",
            "        city state  count\n",
            "33    Denver    CO     22\n",
            "67  Portland    MA     21\n",
            "52  New York    NY     20\n",
            "41   Houston    CO     19\n",
            "37    Denver    OR     18\n",
            "3     Austin    MA     17\n",
            "25    Dallas    CO     17\n",
            "36    Denver    NY     17\n",
            "19   Chicago    MA     17\n",
            "58   Phoenix    IL     17\n"
          ]
        }
      ]
    }
  ]
}